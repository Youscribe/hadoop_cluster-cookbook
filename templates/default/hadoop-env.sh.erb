#!/usr/bin/env bash

#
# Set Hadoop-specific environment variables here.
#
# Created by Chef -- changes will be overwritten
#

# a fence, because bin/hadoop sources this like four times
this_file="`readlink -f $BASH_SOURCE`"
if [ "$HADOOP_ENV_SOURCED" == "" ] || [ "$HADOOP_ENV_SOURCED" != "$this_file" ] ; then

#
# Locations
#

export HADOOP_HOME=<%=     @hadoop[:home_dir] %>
export HADOOP_CONF_DIR=<%= @hadoop[:conf_dir] %>
export HADOOP_LOG_DIR=<%=  @hadoop[:log_dir] %>
export HADOOP_PID_DIR=<%=  @hadoop[:pid_dir] %>
export HADOOP_SLAVES=${HADOOP_HOME}/conf/slaves

export HADOOP_IDENT_STRING=hadoop
export HADOOP_NODENAME="<%= node.name.gsub(/[^\w\-]+/, '') %>"

#
# Java Options
#

# The java implementation to use.  Required.
# export JAVA_HOME=<%= node[:java][:java_home] %>

<%- unless @hadoop[:extra_classpaths].nil? %>
# Extra classpaths for hadoop
export HADOOP_CLASSPATH="<%= @hadoop[:extra_classpaths].values.flatten.join(":") %>:$HADOOP_CLASSPATH"
<%- end %>

# Extra Java runtime options.  Empty by default.
if [ "$HADOOP_OPTS" == "" ]; then export HADOOP_OPTS="-server"; else HADOOP_OPTS+=" -server"; fi

# Ubuntu wants us to use IPv6. Hadoop doesn't support that, but nevertheless binds to :::50010. Let's tell it we don't agree.
export HADOOP_OPTS="$HADOOP_OPTS -Djava.net.preferIPv4Stack=true"

# JVM options
# -XX: The maximum amount of heap to use, in MB. Default is 1000.
export               HADOOP_HEAPSIZE="<%= @hadoop[:java_heap_size_max] %>" # no 'm'
export          HADOOP_NAMENODE_OPTS="-XX:+UseParallelGC -Xmx<%= @hadoop[:namenode   ][:java_heap_size_max] || @hadoop[:java_heap_size_max] %>m $HADOOP_NAMENODE_OPTS"
export HADOOP_SECONDARYNAMENODE_OPTS="-XX:+UseParallelGC -Xmx<%= @hadoop[:secondarynn][:java_heap_size_max] || @hadoop[:java_heap_size_max] %>m $HADOOP_SECONDARYNAMENODE_OPTS"
export        HADOOP_JOBTRACKER_OPTS="-XX:+UseParallelGC -Xmx<%= @hadoop[:jobtracker ][:java_heap_size_max] || @hadoop[:java_heap_size_max] %>m $HADOOP_JOBTRACKER_OPTS"
export          HADOOP_DATANODE_OPTS="-XX:+UseParallelGC -Xmx<%= @hadoop[:datanode   ][:java_heap_size_max] || @hadoop[:java_heap_size_max] %>m $HADOOP_DATANODE_OPTS"
export       HADOOP_TASKTRACKER_OPTS="-XX:+UseParallelGC -Xmx<%= @hadoop[:tasktracker][:java_heap_size_max] || @hadoop[:java_heap_size_max] %>m $HADOOP_TASKTRACKER_OPTS"

# JMX monitoring -- see http://www.cloudera.com/blog/2009/03/hadoop-metrics/
export                   HADOOP_OPTS="-Djava.rmi.server.hostname=<%= @hadoop[:jmx_dash_addr] %> -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false $HADOOP_OPTS"
export          HADOOP_NAMENODE_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=<%= @hadoop[:namenode   ][:jmx_dash_port] %> $HADOOP_NAMENODE_OPTS"
export HADOOP_SECONDARYNAMENODE_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=<%= @hadoop[:secondarynn][:jmx_dash_port] %> $HADOOP_SECONDARYNAMENODE_OPTS"
export        HADOOP_JOBTRACKER_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=<%= @hadoop[:jobtracker ][:jmx_dash_port] %> $HADOOP_JOBTRACKER_OPTS"
export          HADOOP_DATANODE_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=<%= @hadoop[:datanode   ][:jmx_dash_port] %> $HADOOP_DATANODE_OPTS"
export       HADOOP_TASKTRACKER_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=<%= @hadoop[:tasktracker][:jmx_dash_port] %> $HADOOP_TASKTRACKER_OPTS"
export          HADOOP_BALANCER_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=<%= @hadoop[:balancer   ][:jmx_dash_port] %> $HADOOP_BALANCER_OPTS"

#
# Other
#

# The following applies to multiple commands (fs, dfs, fsck, distcp etc)
# export HADOOP_CLIENT_OPTS

# Extra ssh options.  Empty by default.
export HADOOP_SSH_OPTS="-o StrictHostKeyChecking=no"

# Seconds to sleep between slave commands.  Unset by default.  This
# can be useful in large clusters, where, e.g., slave rsyncs can
# otherwise arrive faster than the master can service them.
# export HADOOP_SLAVE_SLEEP=0.1

# The scheduling priority for daemon processes.  See 'man nice'.
# export HADOOP_NICENESS=10

# double-run fence end
export HADOOP_ENV_SOURCED="$this_file"
fi
